- question : ðŸšª backdoor attack
- answer : A type of data poisoning attack where malicious triggers are embedded in the training data, causing the model to behave normally except when the specific trigger is present