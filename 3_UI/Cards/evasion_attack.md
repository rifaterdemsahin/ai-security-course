- question : ğŸƒ evasion attack
- hint : Think about modifying inputs at test time to fool AI models
- answer : A type of adversarial attack where an attacker modifies input data at test time to cause the AI model to make incorrect predictions
- youtubereference : <a href="https://www.youtube.com/watch?v=ZsD2_PO4diU" target="_blank">Evasion Attacks in Machine Learning</a>
- googleimages : <a href="https://www.google.com/search?q=ğŸƒ+evasion+attack+AI+security+machine+learning&tbm=isch" target="_blank">ğŸƒ Evasion Attack Examples and Visualizations</a>
- readingreference : <a href="https://www.google.com/search?q=evasion attack+AI+security+research+papers" target="_blank">evasion attack Research Papers and Articles</a>
