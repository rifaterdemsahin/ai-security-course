- question : ğŸƒ evasion attack
- hint : Think about modifying inputs at test time to fool AI models
- answer : A type of adversarial attack where an attacker modifies input data at test time to cause the AI model to make incorrect predictions
- reference : <a href="https://www.youtube.com/watch?v=ZsD2_PO4diU" target="_blank">Evasion Attacks in Machine Learning</a>