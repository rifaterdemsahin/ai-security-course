<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lesson 1: The Attacker's Playbook - Understanding AI Vulnerabilities</title>
    <link rel="stylesheet" href="../../style.css">
    <style>
        body {
            margin: 0;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        }

        .top-nav {
            background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
            padding: 0;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            position: sticky;
            top: 0;
            z-index: 1000;
        }

        .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 0 20px;
        }

        .nav-brand {
            color: white;
            font-size: 1.5rem;
            font-weight: bold;
            text-decoration: none;
            padding: 15px 0;
        }

        .nav-menu {
            display: flex;
            list-style: none;
            margin: 0;
            padding: 0;
            gap: 10px;
        }

        .nav-item {
            position: relative;
        }

        .nav-link {
            color: white;
            text-decoration: none;
            padding: 15px 20px;
            display: block;
            border-radius: 5px;
            transition: all 0.3s ease;
            font-weight: 500;
        }

        .nav-link:hover {
            background: rgba(255, 255, 255, 0.1);
            transform: translateY(-2px);
        }

        .nav-link.active {
            background: rgba(255, 255, 255, 0.2);
            border-bottom: 3px solid #667eea;
        }

        .lesson-badge {
            background: #667eea;
            color: white;
            font-size: 0.8rem;
            padding: 2px 8px;
            border-radius: 12px;
            margin-left: 8px;
        }

        .home-link {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 5px;
            padding: 8px 15px;
            margin-right: 15px;
        }

        .lesson-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .build-status {
            background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
            color: white;
            padding: 15px 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        .build-info {
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .build-badge {
            background: rgba(255, 255, 255, 0.2);
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 600;
        }

        .deploy-time {
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .github-link {
            color: white;
            text-decoration: none;
            background: rgba(255, 255, 255, 0.1);
            padding: 8px 15px;
            border-radius: 5px;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .github-link:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-2px);
        }
        
        .lesson-header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            border-radius: 10px;
            text-align: center;
            margin-bottom: 30px;
        }
        
        .section {
            background: white;
            margin: 20px 0;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            border-left: 5px solid #667eea;
        }
        
        .section h2 {
            color: #667eea;
            margin-top: 0;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .section-icon {
            font-size: 1.5em;
        }
        
        .objectives {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
        
        .learning-items {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .learning-item {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #28a745;
        }
        
        .duration {
            background: #e9ecef;
            padding: 10px;
            border-radius: 5px;
            display: inline-block;
            margin: 10px 0;
        }
        
        .attack-type {
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .critical-understanding {
            background: #d1ecf1;
            border-left: 4px solid #17a2b8;
            padding: 15px;
            margin: 15px 0;
        }
    </style>
</head>
<body>
    <!-- Top Navigation -->
    <nav class="top-nav">
        <div class="nav-container">
            <a href="../../index.html" class="nav-brand">üõ°Ô∏è AI Security Course</a>
            
            <ul class="nav-menu">
                <li class="nav-item">
                    <a href="../../index.html" class="nav-link home-link">üè† Home</a>
                </li>
                <li class="nav-item">
                    <a href="../Lesson 1/index.html" class="nav-link active">
                        üìö Lesson 1: Attacker's Playbook
                        <span class="lesson-badge">Vulnerabilities</span>
                    </a>
                </li>
                <li class="nav-item">
                    <a href="../Lesson 2/index.html" class="nav-link">
                        üõ°Ô∏è Lesson 2: Building the Shield
                        <span class="lesson-badge" style="background: #28a745;">Defenses</span>
                    </a>
                </li>
                <li class="nav-item">
                    <a href="../Lesson 3/index.html" class="nav-link">
                        üî¥ Lesson 3: Adversarial Testing
                        <span class="lesson-badge" style="background: #dc3545;">Testing</span>
                    </a>
                </li>
            </ul>
        </div>
    </nav>

    <div class="lesson-container">
        <!-- Build Status Section -->
        <div class="build-status">
            <div class="build-info">
                <span class="build-badge">‚úÖ Build Status: Deployed</span>
                <span class="deploy-time">Last Deployed: <span id="deploy-time">2025-10-16 04:14:27 UTC</span></span>
            </div>
            <a href="https://github.com/rifaterdemsahin/ai-security-course/tree/main" target="_blank" class="github-link">
                üì± View on GitHub
            </a>
        </div>
        <div class="lesson-header">
            <h1>Lesson 1: The Attacker's Playbook</h1>
            <p>Understanding AI Vulnerabilities</p>
            <div class="duration">Duration: 60 minutes | Learning Objective: LO1</div>
        </div>

        <!-- TELL Section -->
        <div class="section">
            <h2><span class="section-icon">üìö</span>Tell: Understanding the Concepts</h2>
            
            <div class="objectives">
                <h3>Learning Objectives</h3>
                <p>By the end of this lesson, you will be able to:</p>
                <ul>
                    <li>Analyze and identify security vulnerabilities in AI models</li>
                    <li>Understand the three primary attack categories: evasion, data poisoning, and model extraction</li>
                    <li>Develop an adversarial mindset for security analysis</li>
                    <li>Recognize the difference between test accuracy and adversarial robustness</li>
                </ul>
            </div>

            <h3>Core Concepts</h3>
            
            <div class="attack-type">
                <h4>üéØ Evasion Attacks - Fooling the Model's Senses</h4>
                <p><strong>The Accuracy Paradox:</strong> A model with 99% accuracy can still be dangerously insecure.</p>
                <ul>
                    <li>Adversaries craft inputs that look normal but break model logic</li>
                    <li>Difference between test accuracy and adversarial robustness</li>
                    <li>Example: Stop sign stickers that fool self-driving cars</li>
                </ul>
            </div>

            <div class="attack-type">
                <h4>üîç Data Poisoning - Corrupting Intelligence from Within</h4>
                <p><strong>The Sleeper Agent Attack:</strong> AI models can be turned into "sleeper agents" without detection.</p>
                <ul>
                    <li>Backdoors embedded during the training phase</li>
                    <li>Poisoned models appear to function perfectly</li>
                    <li>Specific inputs activate malicious behavior</li>
                    <li>Training-time vs. test-time attacks</li>
                </ul>
            </div>

            <div class="attack-type">
                <h4>üíª Model Stealing and Extraction - The Digital Heist</h4>
                <p><strong>The Invisible Theft:</strong> Stealing AI's 'secret sauce' without touching the code.</p>
                <ul>
                    <li>Query-based attacks through API calls</li>
                    <li>Model extraction with black-box access</li>
                    <li>Recognizing extraction attempts</li>
                    <li>Intellectual property theft concerns</li>
                </ul>
            </div>

            <div class="critical-understanding">
                <h4>üéØ Critical Understanding</h4>
                <p>AI systems are not infallible black boxes; they are software with unique vulnerabilities. You must learn to see models through the eyes of an attacker, recognizing how they can be manipulated through various attack vectors.</p>
            </div>
        </div>

        <!-- SHOW Section -->
        <div class="section">
            <h2><span class="section-icon">üëÅÔ∏è</span>Show: Real-World Examples and Demonstrations</h2>
            
            <div class="learning-items">
                <div class="learning-item">
                    <h4>üöó Stop Sign Attack on Self-Driving Cars</h4>
                    <p>Researchers demonstrated how simple stickers on a stop sign can trick image recognition systems into misclassifying it as a speed limit sign.</p>
                    <div class="duration">Impact: Catastrophic model failure in safety-critical systems</div>
                </div>

                <div class="learning-item">
                    <h4>üõ°Ô∏è Coach Dialogue: The Trojan Horse in the Code</h4>
                    <p>Interactive scenario: You're a lead ML Engineer whose AI-powered malware detector failed to detect a novel ransomware variant, resulting in a client breach.</p>
                    <div class="duration">Duration: 10-15 minutes</div>
                </div>

                <div class="learning-item">
                    <h4>üìπ Video Demonstrations</h4>
                    <ul>
                        <li>Evasion attacks in action (7.5 min)</li>
                        <li>Data poisoning backdoor activation (7.5 min)</li>
                        <li>Model extraction through API queries (7.5 min)</li>
                    </ul>
                </div>

                <div class="learning-item">
                    <h4>üîç Case Study Analysis</h4>
                    <p>Examine real incidents where AI systems were compromised, analyzing the attack vectors and impact on organizations.</p>
                </div>
            </div>
        </div>

        <!-- DO Section -->
        <div class="section">
            <h2><span class="section-icon">üõ†Ô∏è</span>Do: Hands-On Activities</h2>
            
            <div class="learning-items">
                <div class="learning-item">
                    <h4>üéØ Attack Simulation Lab</h4>
                    <p>Practice crafting adversarial examples against a sample image classifier:</p>
                    <ul>
                        <li>Generate evasion attacks using gradient-based methods</li>
                        <li>Observe how small perturbations fool the model</li>
                        <li>Measure attack success rates</li>
                    </ul>
                </div>

                <div class="learning-item">
                    <h4>üïµÔ∏è Vulnerability Assessment</h4>
                    <p>Analyze a provided AI model for potential weaknesses:</p>
                    <ul>
                        <li>Identify potential attack surfaces</li>
                        <li>Document vulnerability types</li>
                        <li>Assess risk levels</li>
                    </ul>
                </div>

                <div class="learning-item">
                    <h4>üìä Attack Pattern Recognition</h4>
                    <p>Study datasets containing normal and adversarial examples:</p>
                    <ul>
                        <li>Learn to spot manipulation patterns</li>
                        <li>Practice visual inspection techniques</li>
                        <li>Use statistical analysis tools</li>
                    </ul>
                </div>

                <div class="learning-item">
                    <h4>üî¨ Incident Response Simulation</h4>
                    <p>Role-play responding to a security breach:</p>
                    <ul>
                        <li>Investigate the attack vector</li>
                        <li>Assess damage and scope</li>
                        <li>Propose remediation steps</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- APPLY Section -->
        <div class="section">
            <h2><span class="section-icon">üöÄ</span>Apply: Real-World Application</h2>
            
            <div class="objectives">
                <h3>Capstone Project: Security Assessment Report</h3>
                <p>Create a comprehensive security assessment for a real or simulated AI system in your domain of interest.</p>
            </div>

            <div class="learning-items">
                <div class="learning-item">
                    <h4>üìã Assessment Framework</h4>
                    <p>Develop a systematic approach to evaluate AI security:</p>
                    <ul>
                        <li>Define threat models for your chosen domain</li>
                        <li>Create vulnerability assessment checklist</li>
                        <li>Establish risk scoring methodology</li>
                    </ul>
                </div>

                <div class="learning-item">
                    <h4>üéØ Target System Analysis</h4>
                    <p>Choose an AI application and perform security analysis:</p>
                    <ul>
                        <li>Healthcare: Medical imaging diagnosis</li>
                        <li>Finance: Fraud detection systems</li>
                        <li>Automotive: Autonomous driving</li>
                        <li>Security: Malware detection</li>
                    </ul>
                </div>

                <div class="learning-item">
                    <h4>üìñ Professional Report</h4>
                    <p>Document your findings in a professional security assessment:</p>
                    <ul>
                        <li>Executive summary with key risks</li>
                        <li>Technical analysis of vulnerabilities</li>
                        <li>Risk prioritization matrix</li>
                        <li>Recommended mitigation strategies</li>
                    </ul>
                </div>

                <div class="learning-item">
                    <h4>üé§ Presentation & Peer Review</h4>
                    <p>Present your assessment to peers for feedback:</p>
                    <ul>
                        <li>10-minute presentation of key findings</li>
                        <li>Q&A session with classmates</li>
                        <li>Peer evaluation of assessment quality</li>
                        <li>Incorporate feedback for final submission</li>
                    </ul>
                </div>
            </div>

            <div class="critical-understanding">
                <h4>üéØ Real-World Connection</h4>
                <p>This assessment mirrors what security professionals do in practice. You're building skills that directly translate to protecting AI systems in production environments.</p>
            </div>
        </div>

        <div class="section">
            <h2>üìà Progress Check</h2>
            <p>Before moving to Lesson 2, ensure you can:</p>
            <ul>
                <li>‚úÖ Identify the three main categories of AI attacks</li>
                <li>‚úÖ Explain why high test accuracy doesn't guarantee security</li>
                <li>‚úÖ Recognize potential attack vectors in AI systems</li>
                <li>‚úÖ Think from an attacker's perspective about AI vulnerabilities</li>
            </ul>
        </div>
    </div>

    <script>
        // Dynamic build status and deployment time
        function updateBuildStatus() {
            const deployTimeElement = document.getElementById('deploy-time');
            
            // Set the base deployment time (this could be replaced by GitHub Actions)
            const baseDeployTime = '2025-10-16 04:14:27 UTC';
            
            // You can make this dynamic by fetching from GitHub API or build system
            // For now, we'll use the provided time but make it updateable
            deployTimeElement.textContent = baseDeployTime;
            
            // Optional: Add real-time updates or fetch from GitHub API
            // fetch('https://api.github.com/repos/rifaterdemsahin/ai-security-course/commits/main')
            //     .then(response => response.json())
            //     .then(data => {
            //         const lastCommitTime = new Date(data.commit.committer.date).toISOString().replace('T', ' ').substring(0, 19) + ' UTC';
            //         deployTimeElement.textContent = lastCommitTime;
            //     })
            //     .catch(error => console.log('Could not fetch latest commit time'));
        }

        // Update build status when page loads
        document.addEventListener('DOMContentLoaded', updateBuildStatus);

        // Optional: Update every 5 minutes
        // setInterval(updateBuildStatus, 300000);
    </script>
</body>
</html>